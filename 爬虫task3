from selenium import webdriver
browser = webdriver.Chrome("C:\Program Files (x86)\Google\Chrome\Application\chromedriver.exe")
browser.get("http://www.baidu.com")

#两个坑，第一 环境变量，实在不行可以直接给chromedriver.exe的文件目录，第二 chromedriver.exe版本一定要和自己的浏览器版本匹配

import time
from selenium import webdriver
from selenium.webdriver.common.action_chains import ActionChains #导入坐标库
#from selenium.webdriver.common.keys import Keys


browser = webdriver.Chrome("C:\Program Files (x86)\Google\Chrome\Application\chromedriver.exe")
url = 'http://mail.163.com/'
browser.get(url)
time.sleep(3)

browser.maximize_window()#打开网页窗口

time.sleep(5)

browser.switch_to.frame(0)#找到邮箱账号登录框对应的iframe,由于网页中iframe的id是动态的，所以不能用id寻找

ActionChains(browser).move_by_offset(1210, 150).click().perform() # 鼠标右键点击

email = browser.find_element_by_name('email')#找到邮箱账号输入框

email.send_keys('********@163.com')#将自己的邮箱地址输入到邮箱账号框中
    
password = browser.find_element_by_name('password')#找到密码输入框
    
password.send_keys('*****')#输入自己的邮箱密码
    
login_em = browser.find_element_by_id('dologin')#找到登陆按钮
    
login_em.click()#点击登陆按钮
      
time.sleep(10)
#成功登录邮箱

代码如下，获取的代理IP保存在proxy_ip_list列表中
from bs4 import BeautifulSoup
import requests
import time

def open_proxy_url(url):
    user_agent = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.119 Safari/537.36'
    headers = {'User-Agent': user_agent}
    try:
        r = requests.get(url, headers = headers, timeout = 20)
        r.raise_for_status()
        r.encoding = r.apparent_encoding
        return r.text
    except:
        print('无法访问网页' + url)


def get_proxy_ip(response):
    proxy_ip_list = []
    soup = BeautifulSoup(response, 'html.parser')
    proxy_ips  = soup.select('.odd')
    for proxy_ip in proxy_ips:
        ip = proxy_ip.select('td')[1].text
        port = proxy_ip.select('td')[2].text
        protocol = proxy_ip.select('td')[5].text
        if protocol in ('HTTP','HTTPS'):
            proxy_ip_list.append(f'{protocol}://{ip}:{port}')
    return proxy_ip_list

if __name__ == '__main__':
    proxy_url = 'https://www.xicidaili.com/'
    text = open_proxy_url(proxy_url)
    proxy_ip_filename = 'proxy_ip.txt'
    with open(proxy_ip_filename, 'w') as f:
        f.write(text)
    text = open(proxy_ip_filename, 'r').read()
    proxy_ip_list = get_proxy_ip(text)
    print(proxy_ip_list)
